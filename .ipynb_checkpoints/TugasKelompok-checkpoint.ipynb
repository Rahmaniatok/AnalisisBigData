{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuEh7lOFNX-z"
   },
   "source": [
    "Tugas 1 adalah tugas kelompok, masing-masing kelompok beranggotakan 3 mahasiswa.\n",
    "Diberikan file Auto.csv yang dapat diunduh dari Google Classroom. Berdasarkan file tersebut buat contoh\n",
    "dari perintah-perintah di bawah ini menggunakan perintah PySpark dalam jupyter notebook. Setiap jawaban\n",
    "harus dapat dijalankan di notebook dan ditunjukkan luarannya. Unggah notebook ke Google Classroom\n",
    "paling lambat hari Kamis, 09 Maret 2023, pukul 24.00. Untuk unggah notebook setiap kelompok diwakili\n",
    "oleh salah satu anggota saja.\n",
    "\n",
    "1. Berikan contoh cara mengambil satu kolom dari sebuah DataFrame PySpark.\n",
    "2. Berikan contoh cara mengambil beberapa kolom dari sebuah DataFrame PySpark.\n",
    "3. Berikan contoh cara mengubah nama sebuah kolom dalam sebuah DataFrame PySpark.\n",
    "4. Berikan contoh cara menghapus sebuah kolom dari sebuah DataFrame PySpark.\n",
    "5. Berikan contoh cara melakukan filter baris dalam sebuah DataFrame PySpark berdasarkan satu kondisi.\n",
    "6. Berikan contoh cara melakukan filter baris dalam sebuah DataFrame PySpark berdasarkan beberapa\n",
    "kondisi.\n",
    "7. Berikan contoh cara melakukan filter baris dalam sebuah DataFrame PySpark berdasarkan sebuah\n",
    "substring dalam sebuah kolom.\n",
    "8. Berikan contoh cara melakukan filter baris dalam sebuah DataFrame PySpark berdasarkan sebuah\n",
    "regular expression dalam sebuah kolom.\n",
    "9. Berikan contoh cara melakukan filter baris dalam sebuah DataFrame PySpark berdasarkan sebuah\n",
    "daftar nilai dalam sebuah kolom.\n",
    "10. Berikan contoh cara melakukan filter baris dalam sebuah DataFrame PySpark berdasarkan sebuah\n",
    "rentang nilai dalam sebuah kolom.\n",
    "11. Berikan contoh cara melakukan filter baris dalam sebuah DataFrame PySpark berdasarkan nilai null\n",
    "atau non-null dalam sebuah kolom.\n",
    "12. Berikan contoh cara menggabungkan beberapa kondisi filter dalam sebuah DataFrame PySpark.\n",
    "13. Berikan contoh cara melakukan sorting dalam sebuah DataFrame PySpark berdasarkan satu atau\n",
    "beberapa kolom.\n",
    "14. Berikan contoh cara menggunakan fungsi-fungsi SQL PySpark untuk mengubah nilai kolom sebelum\n",
    "melakukan filter.\n",
    "15. Berikan contoh cara menghitung jumlah baris dalam setiap kelompok dari sebuah DataFrame PySpark.\n",
    "16. Berikan contoh cara menghitung jumlah, rata-rata, minimum, dan maksimum dari sebuah kolom\n",
    "numerik untuk setiap kelompok dalam sebuah DataFrame PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skfN_CKdOgrX",
    "outputId": "7b14ebbb-df6a-4095-c6da-e5fd5a0ecf96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jV0majsNWku"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ehb5KsbcQaAp",
    "outputId": "e7899050-bf98-457c-dd36-8c2299f32788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=fae7c0520a981924b38302a229e23cd97e5e6a1f54a597fd4c11b93787f5fcd4\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OI6VaH-KQIAW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import Column\n",
    "from pyspark.sql.functions import upper\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TmpWFn2N5l-"
   },
   "outputs": [],
   "source": [
    "book = spark.read.text(\"/content/drive/MyDrive/Colab Notebooks/Auto (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGClWLvbSbS2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6B-U1WBRAjr"
   },
   "outputs": [],
   "source": [
    "#3\n",
    "df = book.selectExpr(\"\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
